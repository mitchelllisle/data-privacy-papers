[
  {
    "id" : "http://arxiv.org/abs/2505.00593v1",
    "title" : "A Novel Feature-Aware Chaotic Image Encryption Scheme For Data Security\n  and Privacy in IoT and Edge Networks",
    "summary" : "The security of image data in the Internet of Things (IoT) and edge networks\nis crucial due to the increasing deployment of intelligent systems for\nreal-time decision-making. Traditional encryption algorithms such as AES and\nRSA are computationally expensive for resource-constrained IoT devices and\nineffective for large-volume image data, leading to inefficiencies in\nprivacy-preserving distributed learning applications. To address these\nconcerns, this paper proposes a novel Feature-Aware Chaotic Image Encryption\nscheme that integrates Feature-Aware Pixel Segmentation (FAPS) with Chaotic\nChain Permutation and Confusion mechanisms to enhance security while\nmaintaining efficiency. The proposed scheme consists of three stages: (1) FAPS,\nwhich extracts and reorganizes pixels based on high and low edge intensity\nfeatures for correlation disruption; (2) Chaotic Chain Permutation, which\nemploys a logistic chaotic map with SHA-256-based dynamically updated keys for\nblock-wise permutation; and (3) Chaotic chain Confusion, which utilises\ndynamically generated chaotic seed matrices for bitwise XOR operations.\nExtensive security and performance evaluations demonstrate that the proposed\nscheme significantly reduces pixel correlation -- almost zero, achieves high\nentropy values close to 8, and resists differential cryptographic attacks. The\noptimum design of the proposed scheme makes it suitable for real-time\ndeployment in resource-constrained environments.",
    "updated" : "2025-05-01T15:26:48Z",
    "published" : "2025-05-01T15:26:48Z",
    "authors" : [
      {
        "name" : "Muhammad Shahbaz Khan"
      },
      {
        "name" : "Ahmed Al-Dubai"
      },
      {
        "name" : "Jawad Ahmad"
      },
      {
        "name" : "Nikolaos Pitropakis"
      },
      {
        "name" : "Baraq Ghaleb"
      }
    ],
    "categories" : [
      "cs.CR"
    ]
  },
  {
    "id" : "http://arxiv.org/abs/2505.00257v1",
    "title" : "Graph Privacy: A Heterogeneous Federated GNN for Trans-Border Financial\n  Data Circulation",
    "summary" : "The sharing of external data has become a strong demand of financial\ninstitutions, but the privacy issue has led to the difficulty of\ninterconnecting different platforms and the low degree of data openness. To\neffectively solve the privacy problem of financial data in trans-border flow\nand sharing, to ensure that the data is available but not visible, to realize\nthe joint portrait of all kinds of heterogeneous data of business organizations\nin different industries, we propose a Heterogeneous Federated Graph Neural\nNetwork (HFGNN) approach. In this method, the distribution of heterogeneous\nbusiness data of trans-border organizations is taken as subgraphs, and the\nsharing and circulation process among subgraphs is constructed as a\nstatistically heterogeneous global graph through a central server. Each\nsubgraph learns the corresponding personalized service model through local\ntraining to select and update the relevant subset of subgraphs with aggregated\nparameters, and effectively separates and combines topological and feature\ninformation among subgraphs. Finally, our simulation experimental results show\nthat the proposed method has higher accuracy performance and faster convergence\nspeed than existing methods.",
    "updated" : "2025-05-01T02:47:43Z",
    "published" : "2025-05-01T02:47:43Z",
    "authors" : [
      {
        "name" : "Zhizhong Tan"
      },
      {
        "name" : "Jiexin Zheng"
      },
      {
        "name" : "Kevin Qi Zhang"
      },
      {
        "name" : "Wenyong Wang"
      }
    ],
    "categories" : [
      "cs.LG",
      "cs.CR"
    ]
  },
  {
    "id" : "http://arxiv.org/abs/2505.01292v1",
    "title" : "Fine-grained Manipulation Attacks to Local Differential Privacy\n  Protocols for Data Streams",
    "summary" : "Local Differential Privacy (LDP) enables massive data collection and analysis\nwhile protecting end users' privacy against untrusted aggregators. It has been\napplied to various data types (e.g., categorical, numerical, and graph data)\nand application settings (e.g., static and streaming). Recent findings indicate\nthat LDP protocols can be easily disrupted by poisoning or manipulation\nattacks, which leverage injected/corrupted fake users to send crafted data\nconforming to the LDP reports. However, current attacks primarily target static\nprotocols, neglecting the security of LDP protocols in the streaming settings.\nOur research fills the gap by developing novel fine-grained manipulation\nattacks to LDP protocols for data streams. By reviewing the attack surfaces in\nexisting algorithms, We introduce a unified attack framework with composable\nmodules, which can manipulate the LDP estimated stream toward a target stream.\nOur attack framework can adapt to state-of-the-art streaming LDP algorithms\nwith different analytic tasks (e.g., frequency and mean) and LDP models\n(event-level, user-level, w-event level). We validate our attacks theoretically\nand through extensive experiments on real-world datasets, and finally explore a\npossible defense mechanism for mitigating these attacks.",
    "updated" : "2025-05-02T14:09:56Z",
    "published" : "2025-05-02T14:09:56Z",
    "authors" : [
      {
        "name" : "Xinyu Li"
      },
      {
        "name" : "Xuebin Ren"
      },
      {
        "name" : "Shusen Yang"
      },
      {
        "name" : "Liang Shi"
      },
      {
        "name" : "Chia-Mu Yu"
      }
    ],
    "categories" : [
      "cs.CR"
    ]
  },
  {
    "id" : "http://arxiv.org/abs/2505.00951v1",
    "title" : "Preserving Privacy and Utility in LLM-Based Product Recommendations",
    "summary" : "Large Language Model (LLM)-based recommendation systems leverage powerful\nlanguage models to generate personalized suggestions by processing user\ninteractions and preferences. Unlike traditional recommendation systems that\nrely on structured data and collaborative filtering, LLM-based models process\ntextual and contextual information, often using cloud-based infrastructure.\nThis raises privacy concerns, as user data is transmitted to remote servers,\nincreasing the risk of exposure and reducing control over personal information.\nTo address this, we propose a hybrid privacy-preserving recommendation\nframework which separates sensitive from nonsensitive data and only shares the\nlatter with the cloud to harness LLM-powered recommendations. To restore lost\nrecommendations related to obfuscated sensitive data, we design a\nde-obfuscation module that reconstructs sensitive recommendations locally.\nExperiments on real-world e-commerce datasets show that our framework achieves\nalmost the same recommendation utility with a system which shares all data with\nan LLM, while preserving privacy to a large extend. Compared to\nobfuscation-only techniques, our approach improves HR@10 scores and category\ndistribution alignment, offering a better balance between privacy and\nrecommendation quality. Furthermore, our method runs efficiently on\nconsumer-grade hardware, making privacy-aware LLM-based recommendation systems\npractical for real-world use.",
    "updated" : "2025-05-02T01:54:08Z",
    "published" : "2025-05-02T01:54:08Z",
    "authors" : [
      {
        "name" : "Tina Khezresmaeilzadeh"
      },
      {
        "name" : "Jiang Zhang"
      },
      {
        "name" : "Dimitrios Andreadis"
      },
      {
        "name" : "Konstantinos Psounis"
      }
    ],
    "categories" : [
      "cs.IR",
      "cs.CR",
      "cs.LG"
    ]
  }
]