[
  {
    "id" : "http://arxiv.org/abs/1810.09152v2",
    "title" : "PriSTE: From Location Privacy to Spatiotemporal Event Privacy",
    "summary" : "Location privacy-preserving mechanisms (LPPMs) have been extensively studied for protecting a user's location at each time point or a sequence of locations with different timestamps (i.e., a trajectory). We argue that existing LPPMs are not capable of protecting the sensitive information in user's spatiotemporal activities, such as \"visited hospital in the last week\" or \"regularly commuting between Address 1 and Address 2 every morning and afternoon\" (it is easy to infer that Addresses 1 and 2 may be home and office). We define such privacy as \\textit{Spatiotemporal Event Privacy}, which can be formalized as Boolean expressions between location and time predicates. To understand how much spatiotemporal event privacy that existing LPPMs can provide, we first formally define spatiotemporal event privacy by extending the notion of differential privacy, and then provide a framework for calculating the spatiotemporal event privacy loss of a given LPPM under attackers who have knowledge of user's mobility pattern. We also show a case study of utilizing our framework to convert the state-of-the-art mechanism for location privacy, i.e., Planner Laplace Mechanism for Geo-indistinguishability, into one protecting spatiotemporal event privacy. Our experiments on real-life and synthetic data verified that the proposed method is effective and efficient.",
    "updated" : "2020-12-09T01:09:45Z",
    "published" : "2018-10-22T09:41:51Z",
    "authors" : [
      {
        "name" : "Yang Cao"
      },
      {
        "name" : "Yonghui Xiao"
      },
      {
        "name" : "Li Xiong"
      },
      {
        "name" : "Liquan Bai"
      }
    ],
    "categories" : [
      "cs.DB"
    ]
  },
  {
    "id" : "http://arxiv.org/abs/1810.00877v2",
    "title" : "Privacy and Utility Tradeoff in Approximate Differential Privacy",
    "summary" : "We characterize the minimum noise amplitude and power for noise-adding mechanisms in $(ε, δ)$-differential privacy for single real-valued query function. We derive new lower bounds using the duality of linear programming, and new upper bounds by proposing a new class of $(ε,δ)$-differentially private mechanisms, the \\emph{truncated Laplacian} mechanisms. We show that the multiplicative gap of the lower bounds and upper bounds goes to zero in various high privacy regimes, proving the tightness of the lower and upper bounds and thus establishing the optimality of the truncated Laplacian mechanism. In particular, our results close the previous constant multiplicative gap in the discrete setting. Numeric experiments show the improvement of the truncated Laplacian mechanism over the optimal Gaussian mechanism in all privacy regimes.",
    "updated" : "2019-02-06T01:16:17Z",
    "published" : "2018-10-01T17:54:17Z",
    "authors" : [
      {
        "name" : "Quan Geng"
      },
      {
        "name" : "Wei Ding"
      },
      {
        "name" : "Ruiqi Guo"
      },
      {
        "name" : "Sanjiv Kumar"
      }
    ],
    "categories" : [
      "cs.CR",
      "cs.LG"
    ]
  }
]