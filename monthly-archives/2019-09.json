[
  {
    "id" : "http://arxiv.org/abs/1909.04421v4",
    "title" : "Privacy-Preserving Bandits",
    "summary" : "Contextual bandit algorithms~(CBAs) often rely on personal data to provide recommendations. Centralized CBA agents utilize potentially sensitive data from recent interactions to provide personalization to end-users. Keeping the sensitive data locally, by running a local agent on the user's device, protects the user's privacy, however, the agent requires longer to produce useful recommendations, as it does not leverage feedback from other users. This paper proposes a technique we call Privacy-Preserving Bandits (P2B); a system that updates local agents by collecting feedback from other local agents in a differentially-private manner. Comparisons of our proposed approach with a non-private, as well as a fully-private (local) system, show competitive performance on both synthetic benchmarks and real-world data. Specifically, we observed only a decrease of 2.6% and 3.6% in multi-label classification accuracy, and a CTR increase of 0.0025 in online advertising for a privacy budget $ε\\approx 0.693$. These results suggest P2B is an effective approach to challenges arising in on-device privacy-preserving personalization.",
    "updated" : "2020-03-12T00:12:47Z",
    "published" : "2019-09-10T11:39:58Z",
    "authors" : [
      {
        "name" : "Mohammad Malekzadeh"
      },
      {
        "name" : "Dimitrios Athanasakis"
      },
      {
        "name" : "Hamed Haddadi"
      },
      {
        "name" : "Benjamin Livshits"
      }
    ],
    "categories" : [
      "cs.LG",
      "cs.CR",
      "cs.MA",
      "stat.ML"
    ]
  },
  {
    "id" : "http://arxiv.org/abs/1909.01862v1",
    "title" : "Privacy with Surgical Robotics: Challenges in Applying Contextual Privacy Theory",
    "summary" : "The use of connected surgical robotics to automate medical procedures presents new privacy challenges. We argue that conventional patient consent protocols no longer work. Indeed robots that replace human surgeons take on an extraordinary level of responsibility. Surgeons undergo years of training and peer review in a strongly regulated environment, and derive trust via a patient's faith in the hospital system. Robots on the other hand derive trust differently, via the integrity of the software that governs their operation. From a privacy perspective, there are two fundamental shifts. First, the threat model has shifted from one where the humans involved were untrusted to one where the robotic software is untrusted. Second, the basic unit of privacy control is no longer a medical record, but is replaced by four new basic units: the subject on which the robot is taking action; the tools used by the robot; the sensors (i.e data) the robot can access; and, finally access to monitoring and calibration services which afford correct operation of the robot. We suggest that contextual privacy provides useful theoretical tools to solve the privacy problems posed by surgical robots. However, it also poses some challenges: not least that the complexity of the contextual-privacy policies, if rigorously specified to achieve verification and enforceability, will be exceedingly high to directly expose to humans that review contextual privacy policies. A medical robot works with both information and physical material. While informational norms allow for judgements about contextual integrity and the transmission principle governs the constraints applied on information transfer, nothing is said about material property. Certainly, contextual privacy provides an anchor for useful notions of privacy in this scenario and thus should be considered to be extended to cover both information and material flows.",
    "updated" : "2019-09-05T00:17:36Z",
    "published" : "2019-09-04T15:09:24Z",
    "authors" : [
      {
        "name" : "Ryan Shah"
      },
      {
        "name" : "Shishir Nagaraja"
      }
    ],
    "categories" : [
      "cs.CR",
      "cs.RO"
    ]
  },
  {
    "id" : "http://arxiv.org/abs/1909.04421v4",
    "title" : "Privacy-Preserving Bandits",
    "summary" : "Contextual bandit algorithms~(CBAs) often rely on personal data to provide recommendations. Centralized CBA agents utilize potentially sensitive data from recent interactions to provide personalization to end-users. Keeping the sensitive data locally, by running a local agent on the user's device, protects the user's privacy, however, the agent requires longer to produce useful recommendations, as it does not leverage feedback from other users. This paper proposes a technique we call Privacy-Preserving Bandits (P2B); a system that updates local agents by collecting feedback from other local agents in a differentially-private manner. Comparisons of our proposed approach with a non-private, as well as a fully-private (local) system, show competitive performance on both synthetic benchmarks and real-world data. Specifically, we observed only a decrease of 2.6% and 3.6% in multi-label classification accuracy, and a CTR increase of 0.0025 in online advertising for a privacy budget $ε\\approx 0.693$. These results suggest P2B is an effective approach to challenges arising in on-device privacy-preserving personalization.",
    "updated" : "2020-03-11T12:39:06Z",
    "published" : "2019-09-10T11:39:58Z",
    "authors" : [
      {
        "name" : "Mohammad Malekzadeh"
      },
      {
        "name" : "Dimitrios Athanasakis"
      },
      {
        "name" : "Hamed Haddadi"
      },
      {
        "name" : "Benjamin Livshits"
      }
    ],
    "categories" : [
      "cs.LG",
      "cs.CR",
      "cs.MA",
      "stat.ML"
    ]
  },
  {
    "id" : "http://arxiv.org/abs/1909.01862v1",
    "title" : "Privacy with Surgical Robotics: Challenges in Applying Contextual Privacy Theory",
    "summary" : "The use of connected surgical robotics to automate medical procedures presents new privacy challenges. We argue that conventional patient consent protocols no longer work. Indeed robots that replace human surgeons take on an extraordinary level of responsibility. Surgeons undergo years of training and peer review in a strongly regulated environment, and derive trust via a patient's faith in the hospital system. Robots on the other hand derive trust differently, via the integrity of the software that governs their operation. From a privacy perspective, there are two fundamental shifts. First, the threat model has shifted from one where the humans involved were untrusted to one where the robotic software is untrusted. Second, the basic unit of privacy control is no longer a medical record, but is replaced by four new basic units: the subject on which the robot is taking action; the tools used by the robot; the sensors (i.e data) the robot can access; and, finally access to monitoring and calibration services which afford correct operation of the robot. We suggest that contextual privacy provides useful theoretical tools to solve the privacy problems posed by surgical robots. However, it also poses some challenges: not least that the complexity of the contextual-privacy policies, if rigorously specified to achieve verification and enforceability, will be exceedingly high to directly expose to humans that review contextual privacy policies. A medical robot works with both information and physical material. While informational norms allow for judgements about contextual integrity and the transmission principle governs the constraints applied on information transfer, nothing is said about material property. Certainly, contextual privacy provides an anchor for useful notions of privacy in this scenario and thus should be considered to be extended to cover both information and material flows.",
    "updated" : "2019-09-04T15:09:24Z",
    "published" : "2019-09-04T15:09:24Z",
    "authors" : [
      {
        "name" : "Ryan Shah"
      },
      {
        "name" : "Shishir Nagaraja"
      }
    ],
    "categories" : [
      "cs.CR",
      "cs.RO"
    ]
  }
]