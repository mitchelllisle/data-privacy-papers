[
  {
    "id" : "http://arxiv.org/abs/2004.11131v2",
    "title" : "Privacy at Scale: Introducing the PrivaSeer Corpus of Web Privacy Policies",
    "summary" : "Organisations disclose their privacy practices by posting privacy policies on their website. Even though users often care about their digital privacy, they often don't read privacy policies since they require a significant investment in time and effort. Although natural language processing can help in privacy policy understanding, there has been a lack of large scale privacy policy corpora that could be used to analyse, understand, and simplify privacy policies. Thus, we create PrivaSeer, a corpus of over one million English language website privacy policies, which is significantly larger than any previously available corpus. We design a corpus creation pipeline which consists of crawling the web followed by filtering documents using language detection, document classification, duplicate and near-duplication removal, and content extraction. We investigate the composition of the corpus and show results from readability tests, document similarity, keyphrase extraction, and explored the corpus through topic modeling.",
    "updated" : "2024-04-02T00:48:55Z",
    "published" : "2020-04-23T13:21:00Z",
    "authors" : [
      {
        "name" : "Mukund Srinath"
      },
      {
        "name" : "Shomir Wilson"
      },
      {
        "name" : "C. Lee Giles"
      }
    ],
    "categories" : [
      "cs.IR",
      "cs.CR"
    ]
  },
  {
    "id" : "http://arxiv.org/abs/2004.09481v4",
    "title" : "Connecting Robust Shuffle Privacy and Pan-Privacy",
    "summary" : "In the \\emph{shuffle model} of differential privacy, data-holding users send randomized messages to a secure shuffler, the shuffler permutes the messages, and the resulting collection of messages must be differentially private with regard to user data. In the \\emph{pan-private} model, an algorithm processes a stream of data while maintaining an internal state that is differentially private with regard to the stream data. We give evidence connecting these two apparently different models.\n  Our results focus on \\emph{robustly} shuffle private protocols, whose privacy guarantees are not greatly affected by malicious users. First, we give robustly shuffle private protocols and upper bounds for counting distinct elements and uniformity testing. Second, we use pan-private lower bounds to prove robustly shuffle private lower bounds for both problems. Focusing on the dependence on the domain size $k$, we find that robust approximate shuffle privacy and approximate pan-privacy have additive error $Θ(\\sqrt{k})$ for counting distinct elements. For uniformity testing, we give a robust approximate shuffle private protocol with sample complexity $\\tilde O(k^{2/3})$ and show that an $Ω(k^{2/3})$ dependence is necessary for any robust pure shuffle private tester. Finally, we show that this connection is useful in both directions: we give a pan-private adaptation of recent work on shuffle private histograms and use it to recover further separations between pan-privacy and interactive local privacy.",
    "updated" : "2020-08-13T00:09:06Z",
    "published" : "2020-04-20T17:58:14Z",
    "authors" : [
      {
        "name" : "Victor Balcer"
      },
      {
        "name" : "Albert Cheu"
      },
      {
        "name" : "Matthew Joseph"
      },
      {
        "name" : "Jieming Mao"
      }
    ],
    "categories" : [
      "cs.CR",
      "cs.LG"
    ]
  },
  {
    "id" : "http://arxiv.org/abs/2004.02047v1",
    "title" : "Privacy Shadow: Measuring Node Predictability and Privacy Over Time",
    "summary" : "The structure of network data enables simple predictive models to leverage local correlations between nodes to high accuracy on tasks such as attribute and link prediction. While this is useful for building better user models, it introduces the privacy concern that a user's data may be re-inferred from the network structure, after they leave the application. We propose the privacy shadow for measuring how long a user remains predictive from an arbitrary time within the network. Furthermore, we demonstrate that the length of the privacy shadow can be predicted for individual users in three real-world datasets.",
    "updated" : "2020-04-07T00:11:34Z",
    "published" : "2020-04-04T23:31:32Z",
    "authors" : [
      {
        "name" : "Ivan Brugere"
      },
      {
        "name" : "Tanya y. Berger-Wolf"
      }
    ],
    "categories" : [
      "cs.SI",
      "cs.AI"
    ]
  },
  {
    "id" : "http://arxiv.org/abs/2004.11131v2",
    "title" : "Privacy at Scale: Introducing the PrivaSeer Corpus of Web Privacy Policies",
    "summary" : "Organisations disclose their privacy practices by posting privacy policies on their website. Even though users often care about their digital privacy, they often don't read privacy policies since they require a significant investment in time and effort. Although natural language processing can help in privacy policy understanding, there has been a lack of large scale privacy policy corpora that could be used to analyse, understand, and simplify privacy policies. Thus, we create PrivaSeer, a corpus of over one million English language website privacy policies, which is significantly larger than any previously available corpus. We design a corpus creation pipeline which consists of crawling the web followed by filtering documents using language detection, document classification, duplicate and near-duplication removal, and content extraction. We investigate the composition of the corpus and show results from readability tests, document similarity, keyphrase extraction, and explored the corpus through topic modeling.",
    "updated" : "2024-03-30T12:21:59Z",
    "published" : "2020-04-23T13:21:00Z",
    "authors" : [
      {
        "name" : "Mukund Srinath"
      },
      {
        "name" : "Shomir Wilson"
      },
      {
        "name" : "C. Lee Giles"
      }
    ],
    "categories" : [
      "cs.IR",
      "cs.CR"
    ]
  },
  {
    "id" : "http://arxiv.org/abs/2004.09481v4",
    "title" : "Connecting Robust Shuffle Privacy and Pan-Privacy",
    "summary" : "In the \\emph{shuffle model} of differential privacy, data-holding users send randomized messages to a secure shuffler, the shuffler permutes the messages, and the resulting collection of messages must be differentially private with regard to user data. In the \\emph{pan-private} model, an algorithm processes a stream of data while maintaining an internal state that is differentially private with regard to the stream data. We give evidence connecting these two apparently different models.\n  Our results focus on \\emph{robustly} shuffle private protocols, whose privacy guarantees are not greatly affected by malicious users. First, we give robustly shuffle private protocols and upper bounds for counting distinct elements and uniformity testing. Second, we use pan-private lower bounds to prove robustly shuffle private lower bounds for both problems. Focusing on the dependence on the domain size $k$, we find that robust approximate shuffle privacy and approximate pan-privacy have additive error $Θ(\\sqrt{k})$ for counting distinct elements. For uniformity testing, we give a robust approximate shuffle private protocol with sample complexity $\\tilde O(k^{2/3})$ and show that an $Ω(k^{2/3})$ dependence is necessary for any robust pure shuffle private tester. Finally, we show that this connection is useful in both directions: we give a pan-private adaptation of recent work on shuffle private histograms and use it to recover further separations between pan-privacy and interactive local privacy.",
    "updated" : "2020-08-12T03:45:00Z",
    "published" : "2020-04-20T17:58:14Z",
    "authors" : [
      {
        "name" : "Victor Balcer"
      },
      {
        "name" : "Albert Cheu"
      },
      {
        "name" : "Matthew Joseph"
      },
      {
        "name" : "Jieming Mao"
      }
    ],
    "categories" : [
      "cs.CR",
      "cs.LG"
    ]
  },
  {
    "id" : "http://arxiv.org/abs/2004.02047v1",
    "title" : "Privacy Shadow: Measuring Node Predictability and Privacy Over Time",
    "summary" : "The structure of network data enables simple predictive models to leverage local correlations between nodes to high accuracy on tasks such as attribute and link prediction. While this is useful for building better user models, it introduces the privacy concern that a user's data may be re-inferred from the network structure, after they leave the application. We propose the privacy shadow for measuring how long a user remains predictive from an arbitrary time within the network. Furthermore, we demonstrate that the length of the privacy shadow can be predicted for individual users in three real-world datasets.",
    "updated" : "2020-04-04T23:31:32Z",
    "published" : "2020-04-04T23:31:32Z",
    "authors" : [
      {
        "name" : "Ivan Brugere"
      },
      {
        "name" : "Tanya y. Berger-Wolf"
      }
    ],
    "categories" : [
      "cs.SI",
      "cs.AI"
    ]
  }
]