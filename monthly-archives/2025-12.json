[
  {
    "id" : "http://arxiv.org/abs/2512.01832v1",
    "title" : "A Privacy-Preserving Information-Sharing Protocol for Federated Authentication",
    "summary" : "This paper presents a privacy-preserving protocol for identity registration and information sharing in federated authentication systems. The goal is to enable Identity Providers (IdPs) to detect duplicate or fraudulent identity enrollments without revealing users personal data or enabling cross-domain correlation. The protocol relies on Oblivious Pseudorandom Functions (OPRFs) combined with domain-specific transformations, ensuring that each IdP generates independent pseudonymous identifiers derived from a shared cryptographic service while maintaining full input confidentiality. A central authority maintains a blind registry that records successful and failed identity verifications using only pseudonymous identifiers, allowing global consistency checks without exposing sensitive information or linking users across domains. The proposed construction provides a general and abstract framework suitable for a wide range of federated authentication systems, achieving strong privacy guarantees while supporting effective fraud-prevention mechanisms during identity registration.",
    "updated" : "2025-12-01T16:13:41Z",
    "published" : "2025-12-01T16:13:41Z",
    "authors" : [
      {
        "name" : "Francesco Buccafurri"
      },
      {
        "name" : "Carmen Licciardi"
      }
    ],
    "categories" : [
      "cs.CR"
    ]
  },
  {
    "id" : "http://arxiv.org/abs/2512.01748v1",
    "title" : "SA-ADP: Sensitivity-Aware Adaptive Differential Privacy for Large Language Models",
    "summary" : "Despite advances in the use of large language models (LLMs) in downstream tasks, their ability to memorize information has raised privacy concerns. Therefore, protecting personally identifiable information (PII) during LLM training remains a fundamental challenge. Conventional methods like Differential Privacy-Stochastic Gradient Descent (DP-SGD) provide robust privacy protection via uniform noising, protecting PII regardless of its distinct sensitivity. This comes at the expense of the model's utility, leading to a trade-off. In this paper, we propose SA-ADP, a sensitivity-aware approach that allocates noise based on the sensitivity of individual PII. We evaluated our method on four datasets (ABCD, CUSTOMERSIM, Wikitext-2, and UNSW-NB15 ). Our results show that SA-ADP achieves results comparable to the baseline (No-DP) and the conventional DP-SGD. This means that our method did not degrade the model's utility while still maintaining strong privacy protection.",
    "updated" : "2025-12-01T14:50:59Z",
    "published" : "2025-12-01T14:50:59Z",
    "authors" : [
      {
        "name" : "Stella Etuk"
      },
      {
        "name" : "Ashraf Matrawy"
      }
    ],
    "categories" : [
      "cs.LG"
    ]
  },
  {
    "id" : "http://arxiv.org/abs/2512.02369v1",
    "title" : "SAGE: Style-Adaptive Generalization for Privacy-Constrained Semantic Segmentation Across Domains",
    "summary" : "Domain generalization for semantic segmentation aims to mitigate the degradation in model performance caused by domain shifts. However, in many real-world scenarios, we are unable to access the model parameters and architectural details due to privacy concerns and security constraints. Traditional fine-tuning or adaptation is hindered, leading to the demand for input-level strategies that can enhance generalization without modifying model weights. To this end, we propose a \\textbf{S}tyle-\\textbf{A}daptive \\textbf{GE}neralization framework (\\textbf{SAGE}), which improves the generalization of frozen models under privacy constraints. SAGE learns to synthesize visual prompts that implicitly align feature distributions across styles instead of directly fine-tuning the backbone. Specifically, we first utilize style transfer to construct a diverse style representation of the source domain, thereby learning a set of style characteristics that can cover a wide range of visual features. Then, the model adaptively fuses these style cues according to the visual context of each input, forming a dynamic prompt that harmonizes the image appearance without touching the interior of the model. Through this closed-loop design, SAGE effectively bridges the gap between frozen model invariance and the diversity of unseen domains. Extensive experiments on five benchmark datasets demonstrate that SAGE achieves competitive or superior performance compared to state-of-the-art methods under privacy constraints and outperforms full fine-tuning baselines in all settings.",
    "updated" : "2025-12-02T03:20:22Z",
    "published" : "2025-12-02T03:20:22Z",
    "authors" : [
      {
        "name" : "Qingmei Li"
      },
      {
        "name" : "Yang Zhang"
      },
      {
        "name" : "Peifeng Zhang"
      },
      {
        "name" : "Haohuan Fu"
      },
      {
        "name" : "Juepeng Zheng"
      }
    ],
    "categories" : [
      "cs.CV"
    ]
  },
  {
    "id" : "http://arxiv.org/abs/2512.02301v1",
    "title" : "Quantum Vanguard: Server Optimized Privacy Fortified Federated Intelligence for Future Vehicles",
    "summary" : "This work presents vQFL (vehicular Quantum Federated Learning), a new framework that leverages quantum machine learning techniques to tackle key privacy and security issues in autonomous vehicular networks. Furthermore, we propose a server-side adapted fine-tuning method, ft-VQFL,to achieve enhanced and more resilient performance. By integrating quantum federated learning with differential privacy and quantum key distribution (QKD), our quantum vanguard approach creates a multi-layered defense against both classical and quantum threats while preserving model utility. Extensive experimentation with industry-standard datasets (KITTI, Waymo, and nuScenes) demonstrates that vQFL maintains accuracy comparable to standard QFL while significantly improving privacy guaranties and communication security. Our implementation using various quantum models (VQC, QCNN, and SamplerQNN) reveals minimal performance overhead despite the added security measures. This work establishes a crucial foundation for quantum-resistant autonomous vehicle systems that can operate securely in the post-quantum era while efficiently processing the massive data volumes (20-40TB/day per vehicle) generated by modern autonomous fleets. The modular design of the framework allows for seamless integration with existing vehicular networks, positioning vQFL as an essential component for future intelligent transportation infrastructure.",
    "updated" : "2025-12-02T00:43:48Z",
    "published" : "2025-12-02T00:43:48Z",
    "authors" : [
      {
        "name" : "Dev Gurung"
      },
      {
        "name" : "Shiva Raj Pokhrel"
      }
    ],
    "categories" : [
      "cs.CR"
    ]
  }
]