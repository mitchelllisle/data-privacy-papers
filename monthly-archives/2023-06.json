[
  {
    "id" : "http://arxiv.org/abs/2306.13054v2",
    "title" : "Quantum Pufferfish Privacy: A Flexible Privacy Framework for Quantum Systems",
    "summary" : "We propose a versatile privacy framework for quantum systems, termed quantum pufferfish privacy (QPP). Inspired by classical pufferfish privacy, our formulation generalizes and addresses limitations of quantum differential privacy by offering flexibility in specifying private information, feasible measurements, and domain knowledge. We show that QPP can be equivalently formulated in terms of the Datta-Leditzky information spectrum divergence, thus providing the first operational interpretation thereof. We reformulate this divergence as a semi-definite program and derive several properties of it, which are then used to prove convexity, composability, and post-processing of QPP mechanisms. Parameters that guarantee QPP of the depolarization mechanism are also derived. We analyze the privacy-utility tradeoff of general QPP mechanisms and, again, study the depolarization mechanism as an explicit instance. The QPP framework is then applied to privacy auditing for identifying privacy violations via a hypothesis testing pipeline that leverages quantum algorithms. Connections to quantum fairness and other quantum divergences are also explored and several variants of QPP are examined.",
    "updated" : "2024-07-18T00:19:40Z",
    "published" : "2023-06-22T17:21:17Z",
    "authors" : [
      {
        "name" : "Theshani Nuradha"
      },
      {
        "name" : "Ziv Goldfeld"
      },
      {
        "name" : "Mark M. Wilde"
      }
    ],
    "categories" : [
      "quant-ph",
      "cs.CR",
      "cs.IT",
      "cs.LG"
    ]
  },
  {
    "id" : "http://arxiv.org/abs/2306.13214v2",
    "title" : "Prior-itizing Privacy: A Bayesian Approach to Setting the Privacy Budget in Differential Privacy",
    "summary" : "When releasing outputs from confidential data, agencies need to balance the analytical usefulness of the released data with the obligation to protect data subjects' confidentiality. For releases satisfying differential privacy, this balance is reflected by the privacy budget, $\\varepsilon$. We provide a framework for setting $\\varepsilon$ based on its relationship with Bayesian posterior probabilities of disclosure. The agency responsible for the data release decides how much posterior risk it is willing to accept at various levels of prior risk, which implies a unique $\\varepsilon$. Agencies can evaluate different risk profiles to determine one that leads to an acceptable trade-off in risk and utility.",
    "updated" : "2024-05-24T00:54:06Z",
    "published" : "2023-06-19T22:23:09Z",
    "authors" : [
      {
        "name" : "Zeki Kazan"
      },
      {
        "name" : "Jerome P. Reiter"
      }
    ],
    "categories" : [
      "cs.CR",
      "stat.ME"
    ]
  },
  {
    "id" : "http://arxiv.org/abs/2306.10923v1",
    "title" : "Toward the Cure of Privacy Policy Reading Phobia: Automated Generation of Privacy Nutrition Labels From Privacy Policies",
    "summary" : "Software applications have become an omnipresent part of modern society. The consequent privacy policies of these applications play a significant role in informing customers how their personal information is collected, stored, and used. However, customers rarely read and often fail to understand privacy policies because of the ``Privacy Policy Reading Phobia'' (PPRP). To tackle this emerging challenge, we propose the first framework that can automatically generate privacy nutrition labels from privacy policies. Based on our ground truth applications about the Data Safety Report from the Google Play app store, our framework achieves a 0.75 F1-score on generating first-party data collection practices and an average of 0.93 F1-score on general security practices. We also analyse the inconsistencies between ground truth and curated privacy nutrition labels on the market, and our framework can detect 90.1% under-claim issues. Our framework demonstrates decent generalizability across different privacy nutrition label formats, such as Google's Data Safety Report and Apple's App Privacy Details.",
    "updated" : "2023-06-21T00:27:15Z",
    "published" : "2023-06-19T13:33:44Z",
    "authors" : [
      {
        "name" : "Shidong Pan"
      },
      {
        "name" : "Thong Hoang"
      },
      {
        "name" : "Dawen Zhang"
      },
      {
        "name" : "Zhenchang Xing"
      },
      {
        "name" : "Xiwei Xu"
      },
      {
        "name" : "Qinghua Lu"
      },
      {
        "name" : "Mark Staples"
      }
    ],
    "categories" : [
      "cs.CR",
      "cs.SE"
    ]
  },
  {
    "id" : "http://arxiv.org/abs/2306.13054v2",
    "title" : "Quantum Pufferfish Privacy: A Flexible Privacy Framework for Quantum Systems",
    "summary" : "We propose a versatile privacy framework for quantum systems, termed quantum pufferfish privacy (QPP). Inspired by classical pufferfish privacy, our formulation generalizes and addresses limitations of quantum differential privacy by offering flexibility in specifying private information, feasible measurements, and domain knowledge. We show that QPP can be equivalently formulated in terms of the Datta-Leditzky information spectrum divergence, thus providing the first operational interpretation thereof. We reformulate this divergence as a semi-definite program and derive several properties of it, which are then used to prove convexity, composability, and post-processing of QPP mechanisms. Parameters that guarantee QPP of the depolarization mechanism are also derived. We analyze the privacy-utility tradeoff of general QPP mechanisms and, again, study the depolarization mechanism as an explicit instance. The QPP framework is then applied to privacy auditing for identifying privacy violations via a hypothesis testing pipeline that leverages quantum algorithms. Connections to quantum fairness and other quantum divergences are also explored and several variants of QPP are examined.",
    "updated" : "2024-05-28T14:08:52Z",
    "published" : "2023-06-22T17:21:17Z",
    "authors" : [
      {
        "name" : "Theshani Nuradha"
      },
      {
        "name" : "Ziv Goldfeld"
      },
      {
        "name" : "Mark M. Wilde"
      }
    ],
    "categories" : [
      "quant-ph",
      "cs.CR",
      "cs.IT",
      "cs.LG"
    ]
  },
  {
    "id" : "http://arxiv.org/abs/2306.13214v2",
    "title" : "Prior-itizing Privacy: A Bayesian Approach to Setting the Privacy Budget in Differential Privacy",
    "summary" : "When releasing outputs from confidential data, agencies need to balance the analytical usefulness of the released data with the obligation to protect data subjects' confidentiality. For releases satisfying differential privacy, this balance is reflected by the privacy budget, $\\varepsilon$. We provide a framework for setting $\\varepsilon$ based on its relationship with Bayesian posterior probabilities of disclosure. The agency responsible for the data release decides how much posterior risk it is willing to accept at various levels of prior risk, which implies a unique $\\varepsilon$. Agencies can evaluate different risk profiles to determine one that leads to an acceptable trade-off in risk and utility.",
    "updated" : "2024-05-22T16:10:54Z",
    "published" : "2023-06-19T22:23:09Z",
    "authors" : [
      {
        "name" : "Zeki Kazan"
      },
      {
        "name" : "Jerome P. Reiter"
      }
    ],
    "categories" : [
      "cs.CR",
      "stat.ME"
    ]
  },
  {
    "id" : "http://arxiv.org/abs/2306.10923v1",
    "title" : "Toward the Cure of Privacy Policy Reading Phobia: Automated Generation of Privacy Nutrition Labels From Privacy Policies",
    "summary" : "Software applications have become an omnipresent part of modern society. The consequent privacy policies of these applications play a significant role in informing customers how their personal information is collected, stored, and used. However, customers rarely read and often fail to understand privacy policies because of the ``Privacy Policy Reading Phobia'' (PPRP). To tackle this emerging challenge, we propose the first framework that can automatically generate privacy nutrition labels from privacy policies. Based on our ground truth applications about the Data Safety Report from the Google Play app store, our framework achieves a 0.75 F1-score on generating first-party data collection practices and an average of 0.93 F1-score on general security practices. We also analyse the inconsistencies between ground truth and curated privacy nutrition labels on the market, and our framework can detect 90.1% under-claim issues. Our framework demonstrates decent generalizability across different privacy nutrition label formats, such as Google's Data Safety Report and Apple's App Privacy Details.",
    "updated" : "2023-06-19T13:33:44Z",
    "published" : "2023-06-19T13:33:44Z",
    "authors" : [
      {
        "name" : "Shidong Pan"
      },
      {
        "name" : "Thong Hoang"
      },
      {
        "name" : "Dawen Zhang"
      },
      {
        "name" : "Zhenchang Xing"
      },
      {
        "name" : "Xiwei Xu"
      },
      {
        "name" : "Qinghua Lu"
      },
      {
        "name" : "Mark Staples"
      }
    ],
    "categories" : [
      "cs.CR",
      "cs.SE"
    ]
  }
]